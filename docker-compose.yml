version: "3.9"

services:
  qwen:
    image: vllm/vllm-openai:v0.5.4
    container_name: qwen-local
    ports:
      - "8000:8000"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ./models/Qwen2-7B-Instruct-AWQ:/model
    command: >
      --model /model
      --served-model-name qwen
      --host 0.0.0.0
      --port 8000
      --dtype float16
      --max-model-len 8192
      --gpu-memory-utilization 0.90
